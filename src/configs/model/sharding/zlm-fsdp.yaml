
# === Weights ===

# vocab
embed_tokens.weight: [fsdp, null]
lm_head.weight: [fsdp, null]


# encoder
encoder_model.layers.*.self_attn.q_proj.weight: [fsdp, null]
encoder_model.layers.*.self_attn.k_proj.weight: [fsdp, null]
encoder_model.layers.*.self_attn.v_proj.weight: [fsdp, null]
encoder_model.layers.*.self_attn.o_proj.weight: [fsdp, null]

encoder_model.layers.*.mlp.gate_proj.weight: [fsdp, null]
encoder_model.layers.*.mlp.up_proj.weight: [fsdp, null]
encoder_model.layers.*.mlp.down_proj.weight: [null, fsdp]

encoder_model.layers.*.input_layernorm.weight: [null]
encoder_model.layers.*.post_attention_layernorm.weight: [null]
encoder_model.norm.weight: [null]


# decoder
decoder_model.layers.*.self_attn.q_proj.weight: [fsdp, null]
decoder_model.layers.*.self_attn.k_proj.weight: [fsdp, null]
decoder_model.layers.*.self_attn.v_proj.weight: [fsdp, null]
decoder_model.layers.*.self_attn.o_proj.weight: [fsdp, null]

decoder_model.layers.*.mlp.gate_proj.weight: [fsdp, null]
decoder_model.layers.*.mlp.up_proj.weight: [fsdp, null]
decoder_model.layers.*.mlp.down_proj.weight: [null, fsdp]

decoder_model.layers.*.input_layernorm.weight: [null]
decoder_model.layers.*.post_attention_layernorm.weight: [null]
decoder_model.norm.weight: [null]


# scheduler
scheduler.timesteps: [null]
scheduler.a: [null]
scheduler.b: [null]


# diffusion head
diffusion_head.x_t_in_proj.weight: [fsdp, null]
# diffusion_head.hidden_states_in_proj.weight: [fsdp, null]

diffusion_head.layers.*.norm.embed.weight: [null, null]
diffusion_head.layers.*.mlp.gate_proj.weight: [fsdp, null]
diffusion_head.layers.*.mlp.up_proj.weight: [fsdp, null]
diffusion_head.layers.*.mlp.down_proj.weight: [null, fsdp]
diffusion_head.layers.*.out_scale.embed.weight: [null, null]

diffusion_head.out_norm.embed.weight: [null, null]
diffusion_head.out_proj.weight: [null, fsdp]


# uncond diffusion head
uncond_diffusion_head.x_t_in_proj.weight: [fsdp, null]
# uncond_diffusion_head.hidden_states_in_proj.weight: [fsdp, null]

uncond_diffusion_head.layers.*.norm.embed.weight: [null, null]
uncond_diffusion_head.layers.*.mlp.gate_proj.weight: [fsdp, null]
uncond_diffusion_head.layers.*.mlp.up_proj.weight: [fsdp, null]
uncond_diffusion_head.layers.*.mlp.down_proj.weight: [null, fsdp]
uncond_diffusion_head.layers.*.out_scale.embed.weight: [null, null]

uncond_diffusion_head.out_norm.embed.weight: [null, null]
uncond_diffusion_head.out_proj.weight: [null, fsdp]


# external
encoder_sep_token: [null, null]
encoder_z_tokens: [null, fsdp]

decoder_z_tokens: [null, fsdp]
decoder_start_output_token: [null, null]

encoder_input_embeddings: [null]
encoder_output_embeddings: [null]

decoder_input_embeddings: [null]
decoder_output_embeddings: [null]

encoder_noise_proj_in.weight: [fsdp, null]
decoder_z_proj_in.weight: [fsdp, null]

encoder_mu_proj_out.weight: [null, fsdp]

uncond_tokens: [null, fsdp]


# === Activations ===

# input
embed_tokens: [[data, fsdp], null, null]


# transformers
encoder_model.layers.*: [[data, fsdp], null, null]
decoder_model.layers.*: [[data, fsdp], null, null]


# diffusion heads
diffusion_head.layers.*: [[data, fsdp], null, null]
diffusion_head.out_proj: [[data, fsdp], null, null]

uncond_diffusion_head.layers.*: [[data, fsdp], null, null]
uncond_diffusion_head.out_proj: [[data, fsdp], null, null]

# output
encoder_mu_proj_out: [[data, fsdp], null, null]

lm_head: [[data, fsdp], null, null]
